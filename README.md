# ğŸ¤– AI Chatbot using LLM (Full Stack)

> **Live Application:** [https://ai-chatbot-using-llm.vercel.app](https://ai-chatbot-using-llm.vercel.app)

## ğŸ“– Overview

This is a production-grade, domain-specific AI Chatbot capable of intelligent routing, persistent memory, and multi-expert persona management. It features a high-performance **FastAPI** backend that orchestrates stateful conversations using **LangGraph**, connected to a modern **Next.js 14** frontend with a sleek, anti-gravity aesthetic.

The system is designed to simulate a team of industry experts:
- ğŸ“ **Education Expert** (Socratic Tutor)
- âš–ï¸ **Legal Assistant** (Regulatory Guidance)
- ğŸ¥ **Medical Assistant** (Health Protocols)
- âš½ **Sports Analyst** (Data & Strategy)

## ğŸ—ï¸ Architecture

### ğŸ–¥ï¸ Frontend (`/frontend`)
- **Framework:** Next.js 14 (App Router) & TypeScript
- **Styling:** Tailwind CSS + GSAP (Animations) + Lenis (Smooth Scroll)
- **Features:**
    - Dynamic Domain Theming (Colors shift based on active expert).
    - Smart "Switch" UI that detects backend routing suggestions.
    - Chat history management and Markdown rendering.

### âš™ï¸ Backend (`/backend`)
- **Framework:** FastAPI (Python)
- **State Machine:** LangGraph (Manages conversation state & memory).
- **LLM Engine:** Multi-provider support (Groq, OpenAI, Google Gemini, Hugging Face).
- **Intelligence:**
    - **Router:** Automatically detects domain mismatch and proposes switches.
    - **Guardrails:** Strict system prompts prevent off-topic hallucinations.
    - **Memory:** `MemorySaver` persists context across chat turns.

## ğŸ“‚ Repository Structure

```bash
AI_Chatbot_using_LLM/
â”œâ”€â”€ frontend/           # Next.js Application
â”‚   â”œâ”€â”€ src/            # Components, Hooks, and Pages
â”‚   â”œâ”€â”€ public/         # Static Assets
â”‚   â””â”€â”€ ...
â”‚
â”œâ”€â”€ backend/            # FastAPI Application
â”‚   â”œâ”€â”€ api/            # API Routes
â”‚   â”œâ”€â”€ src/            # Core Logic (Graph, Prompts, Nodes)
â”‚   â”œâ”€â”€ Dockerfile      # Deployment Config
â”‚   â””â”€â”€ ...
â”‚
â””â”€â”€ README.md           # Documentation

```

## ğŸš€ Quick Start (Local Development)

You need two terminals running simultaneously to develop locally.

### Terminal 1: Backend

```bash
cd backend
python -m venv .venv
source .venv/bin/activate  # Windows: .venv\Scripts\activate
pip install -r requirements.txt
uvicorn app:app --reload

```

*Backend runs on: `http://localhost:8000*`

### Terminal 2: Frontend

```bash
cd frontend
npm install
npm run dev

```

*Frontend runs on: `http://localhost:3000*`

## ğŸŒ Deployment Status

| Component | Platform | Status |
| --- | --- | --- |
| **Frontend** | Vercel | âœ… Live |
| **Backend** | Hugging Face Spaces | âœ… Live |

## ğŸ¤ Contribution

This project was developed as a comprehensive Full Stack AI Internship project, demonstrating advanced architecture in State Management, API Design, and UI/UX Engineering.